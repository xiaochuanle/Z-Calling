# Z-Calling

## Brief Introduction

Z-Calling is a machine-learning toolkit designed to detect and call 2,6-diaminopurine (Z-base) modifications using PacBio HiFi reads.

## Core Features

- **Molecule Classification:** Distinguishes dZ-DNA molecules from canonical (A) DNA.
- **Base Calling:** Precisely identifies Z bases within hybrid A/Z sequences.
- **Source Detection:** A pipeline to identify taxonomic sources of dZ-DNAs in mixed datasets with zero false positive discovery in benchmarking.

## Performance

Across multiple datasets, the Z base calling module achieves **AUCs of 0.94–0.96** and **F1 scores of 0.85–0.92**.

## Computational Requirements & Installation

### System Requirements
Z-Calling is designed to run on standard Linux environments and does **not** require GPU acceleration.

* **Operating System:** Linux
* **Memory (RAM):** ≥ 32 GB recommended (Peak memory usage is approx. 31 GB during base calling)
* **Processor:** Standard Multi-core CPU (Benchmarked on AMD EPYC 7402 24-Core Processor)
* **Disk Space:** Sufficient space for input BAMs and output files

### Building from Scratch
Z-Calling is designed to run on CPU. The installation process uses Conda (or Mamba) to handle all dependencies automatically, including HTSlib, PyTorch, and the necessary C++ compilers. This eliminates the need for manual library compilation.

#### 1. Download this repository.
```base
git clone https://github.com/xiaochuanle/Z-Calling.git
cd Z-Calling
```

#### 2. Set up the Environment
We strongly recommend using Mamba for faster environment resolution, though standard Conda will also work. The environment.yml file in the root directory of the project.
Run the following commands to create the environment:

```bash
# Option A: Using Mamba (Recommended - Faster)
mamba env create -f environment.yml

# Option B: Using Standard Conda (Slower)
conda env create -f environment.yml
```
Once the environment is created, activate it and test if torch is successfully installed:
```bash
conda activate Z-Calling
python -c "import torch; print(torch.__version__)"  # Successful installation will print '2.2.2+cpu'
```

#### 3. Building the Program
```bash
mkdir build
cd build
cmake ..
make -j
```
Once compilation is complete, the executables (such as z-calling-base and z-bam2txt) will be located in the build/ directory.
Optionally: Add Z-Calling/build to your PATH.

## **Z-Calling Usage**

### **1\. Pre-processing: Filter BAM Reads**

Before analysis, reads must be filtered to remove low-quality data and ensure kinetic signals are present.

**Filtering Criteria:**

1. **Required Tags:** Kinetic signals (fi, ri, fp, rp) must be present.  
2. **Signal Quality:** Reads with Median\_PW / Median\_IPD \< 0.3 or \> 99th percentile are discarded.  
3. **Passes:** Minimum 3 passes required for both forward (fn \>= 3\) and reverse (rn \>= 3\) strands.

python py/filter\_bam.py \-b \<RawBAM\> \-o \<FilteredBAM\>

* **RawBAM**: Input BAM file (mapped or unmapped) containing kinetic tags.  
* **FilteredBAM**: Output path for the clean BAM file.

(Optional) Alignment:  
If your input was unmapped, align the filtered reads to a reference:  
pbmm2 align REF.fasta FilteredBAM FilteredMappingBAM.bam \--preset CCS \--sort

### **2\. Z-Calling (Base & Read Level)**

#### **A. Run the MLP Module (Base Calling)**

Perform base-level modification calling. Choose the model based on your goal.

Available Models:  
The package includes three pre-trained models located in the model/ directory:

1. **model/k21-full-ZA/scripted\_m21.pth** (Use with \-k 21\)  
   * **Purpose:** dZ-DNA read detection.  
   * **Description:** Trained on full-dA/dZ datasets. Intended for classifying entire reads as dZ-modified or native.  
2. **model/k11-mixed-AZ/scripted\_m11.pth** (Use with \-k 11\)  
   * **Purpose:** Single-nucleotide Z/A classification.  
   * **Description:** Adds a ZP tag to reads recording the Z probability for each A/T base. Best for site-specific analysis.

build/z-calling-base \-k \<Kmer\_size\> \-t \<Threads\> \<Input\_BAM\> \<Model\_Path\> \<Output\_BAM\>

| Argument | Description |
| :---- | :---- |
| \-k | **21** for the k21-full-ZA model. **11** for the k11-mixed-AZ model. |
| \-t | Number of CPU threads (default: 16). |
| Input\_BAM | Path to the input BAM file. |
| Model\_Path | Path to the .pth model file (see list above). |
| Output\_BAM | Output BAM file. Modifications are stored in MM and ML tags. |

#### **B. Run SVM Classifier (Read Level)**

Predict the modification status of entire reads using the ZP tags generated by the k21 model.

Model:  
3\. model/svm/k21ReadClassifier: The pre-trained SVM classifier used for this step.  
build/z-calling-read predict \<Input\_BAM\> \<Result\_TSV\> \<Model\_Path\> \<min\_len\> \<intervals\>

* **Model\_Path**: Path to the SVM model (e.g., model/svm/k21ReadClassifier).  
* **min\_len**: Minimum read length to classify (Required: must be **\>= 500**).  
* **intervals**: Number of sections to split the read into for feature extraction (Required: must be exactly **100** for the current model).

Output Format (Result\_TSV):  
The output is a tab-separated file with two columns:

1. **Read Name**  
2. **Classification**:  
   * \+: dZ-DNA (Modified)  
   * \-: Canonical DNA (Unmodified)  
   * Otherwise: Unclassified (likely failed length criteria)

### **3\. Downstream Analysis**

#### **A. Taxonomic Source of dZ-DNA Reads**

To identify the species origin of dZ-DNA reads:

\# 1\. Convert filtered BAM to FASTA  
samtools fasta \-@8 FilteredBAM \> Filtered.fasta

\# 2\. Map to reference and filter for high divergence (suggesting dZ-DNA)  
minimap2 \-t 8 \-x map-hifi $REF Filtered.fasta | \\  
  awk '\!a\[$1\]++' | \\  
  awk '($4-$3/$2)\>0.4 {match($0, /dv:f:(\[0-9.\]+)/, a); if (a\[1\]\<0.05) {print $1"\\t"$6}}' \> read\_RefContig.tsv

\# 3\. Perform LR Analysis  
python py/SVM\_LR\_analysis.py \--SVM z-calling-read-Result\_path \\  
  \--read\_ref read\_RefContig.tsv \\  
  \[ \--ref\_species RefContig\_Spcecies.tsv \] \\  
  \--output SVM.LR.tsv

#### **B. Convert Z-Calls to Table (z-bam2txt)**

Convert the BAM file with ZP tags into a tab-delimited text file.

build/z-bam2txt \-zp \-t 16 \<Input\_BAM\> \- \[Reference\_Fasta\] \> \<Result.tsv\>

Important Note on Reference Fasta:  
While the \[Reference\_Fasta\] argument is optional for basic conversion, it is mandatory if you plan to run zfreq analysis afterwards. You must provide the exact same reference file that was used for the alignment step to ensuring mapping coordinates match.  
**Output Format:**

* Mapped Reads (8 columns):  
  QueryName, ReadID, Strand, QueryPos, Base, RefName, RefPos, Probability  
* Unmapped Reads (6 columns):  
  QueryName, ReadID, Strand, QueryPos, Base, Probability

#### **C. Convert to 6-Alphabet FASTA (z-seq)**

Generate a FASTA file where modified bases are represented by distinct characters.

* **Z**: Represents dZ  
* **O**: Represents a T paired with dZ (on the opposite strand)

build/z-seq \<Input\_BAM\> \<Output.fasta\>

#### **D. Calculate Aggregated Z-Frequencies (zfreq)**

Calculate the ratio of Z bases at each reference coordinate (Z / (A+Z)).

build/zfreq \-i \<Input\_TSV\> \-o \<Output\_Freq.tsv\>

* **Input\_TSV**: The output file from z-bam2txt (must be mapped reads).  
* **Output\_Freq.tsv**: The final frequency report.

**Output Format (zfreq):**

1. **chr**: Reference chromosome name.  
2. **coor**: Reference coordinate.  
3. **num\_records\_above\_threshold**: Count of bases classified as Z (high probability).  
4. **num\_records\_below\_threshold**: Count of bases classified as A (low probability).  
5. **ratio\_above\_threshold**: The Z-ratio (Count\_Z / Total).

## **Example Analysis**
We provide example datasets to test the Z-Calling modules. The data includes:

* **100 dZ-DNA reads** (modified amplicon from E. coli).  
* **100 native DNA reads** (control from E. coli).

### **Running the Test**
To perform the analysis, simply navigate to the example\_data directory and run the automated script:

```bash
conda activate Z-Calling
cd example\_data  
bash run\_examples.sh
```
This script will automatically perform filtering, alignment, base calling, read classification, and frequency analysis.
